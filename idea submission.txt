# problem statement
// copy paste from sih site


# describe oyur idea / solution /prototype


we will be creating an app which can translate voice data to transcript text and than the transcript 
will be converted(optional) to sign language (GIFs/image/video).

there are 3 stages on which we will work on:
1. First step will be to convert speech to text(english).
2. second step will be convert text to sign language / or we can say adding a plugin to convert text to sign language data.
3. Third stage will be including more languages data models to our app since intially we are using English as basic language
   so we will be adding more local languages like Hindi, Marathi , Tamil etc to the app.

Doing all this recognizing and translation work offline would require a lot of data models (data )
so all this work will be done online with the help of cloud.
However we will be providing an option to download all data run the app offline as well.


# describe technology stack here
// to be added


# descirbe use cases

roles : for deaf and hearing impaired persons
UML //to be added
diagram // to be added



# describe your dependencies /show stopper

1. speech to text recoginizing data set / model for other native languages like Hindi, Tamil , Marathi.
2. cloud server to do training and recognination.
3. data set (GIFs, video, images) of sign languages
4. Play store account , to launch the app on play store


